{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "rental-magazine",
   "metadata": {},
   "source": [
    "# Age Classification Project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afraid-equation",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "automatic-special",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "domestic-proposal",
   "metadata": {},
   "outputs": [],
   "source": [
    "from skimage.feature import canny  # for extracting the canny features of the image"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "located-middle",
   "metadata": {},
   "source": [
    "##### The data is present in the folder combined_faces with each image of size 200x200 pixels and named after the images age."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "stretch-davis",
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing all images file names\n",
    "\n",
    "combined_faces_path = \"combined_faces\"\n",
    "combined_faces_image_names = os.listdir(combined_faces_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "concrete-interview",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "33486"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(combined_faces_image_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "optional-vampire",
   "metadata": {},
   "outputs": [],
   "source": [
    "# defining a function to return class labels corresponding to age ranges.\n",
    "\n",
    "def class_labels(age):\n",
    "    if 1 <= age <= 2:\n",
    "        return 0\n",
    "    elif 3 <= age <= 9:\n",
    "        return 1\n",
    "    elif 10 <= age <= 20:\n",
    "        return 2\n",
    "    elif 21 <= age <= 25:\n",
    "        return 3\n",
    "    elif 26 <= age <= 27:\n",
    "        return 4\n",
    "    elif 28 <= age <= 31:\n",
    "        return 5\n",
    "    elif 32 <= age <= 36:\n",
    "        return 6\n",
    "    elif 37 <= age <= 45:\n",
    "        return 7\n",
    "    elif 46 <= age <= 54:\n",
    "        return 8\n",
    "    elif 55 <= age <= 65:\n",
    "        return 9\n",
    "    else:\n",
    "        return 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "palestinian-attraction",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>100_1.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100_10.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>100_11.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>100_12.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100_13.jpg</td>\n",
       "      <td>100</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  age  target\n",
       "0   100_1.jpg  100      10\n",
       "1  100_10.jpg  100      10\n",
       "2  100_11.jpg  100      10\n",
       "3  100_12.jpg  100      10\n",
       "4  100_13.jpg  100      10"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a dataframe consisting of filenames and corresponding ages and classes.\n",
    "\n",
    "master_df = pd.DataFrame()\n",
    "master_df['filename'] = combined_faces_image_names\n",
    "master_df['age'] = master_df['filename'].map(lambda img_name : int(img_name.split(\"_\")[0]))\n",
    "master_df['target'] = master_df['age'].map(class_labels)\n",
    "\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "disciplinary-ladder",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>43_174.jpg</td>\n",
       "      <td>43</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37_21.jpg</td>\n",
       "      <td>37</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1_1765.jpg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>38_403.jpg</td>\n",
       "      <td>38</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42_127.jpg</td>\n",
       "      <td>42</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     filename  age  target\n",
       "0  43_174.jpg   43       7\n",
       "1   37_21.jpg   37       7\n",
       "2  1_1765.jpg    1       0\n",
       "3  38_403.jpg   38       7\n",
       "4  42_127.jpg   42       7"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# shuffling the rows of master_df to mix the dataset\n",
    "\n",
    "master_df = shuffle(master_df, random_state=11).reset_index(drop=True)\n",
    "master_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "blessed-shield",
   "metadata": {},
   "outputs": [],
   "source": [
    "# seperating features and targets\n",
    "\n",
    "X = master_df[['filename', 'age']]\n",
    "Y = master_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "patent-genetics",
   "metadata": {},
   "outputs": [],
   "source": [
    "# splitting the dataset into training and testing\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "atomic-throw",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26788, 2)\n",
      "(6698, 2)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "alpha-andrews",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.104450\n",
       "7     0.097282\n",
       "4     0.095491\n",
       "0     0.094520\n",
       "6     0.093400\n",
       "2     0.093101\n",
       "5     0.091086\n",
       "1     0.084217\n",
       "9     0.083097\n",
       "8     0.082686\n",
       "10    0.080670\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution in all the classes for train data\n",
    "\n",
    "y_train.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "extra-airport",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.100926\n",
       "0     0.098537\n",
       "4     0.098388\n",
       "2     0.095850\n",
       "5     0.093013\n",
       "7     0.089728\n",
       "8     0.087638\n",
       "6     0.087190\n",
       "9     0.085100\n",
       "1     0.083607\n",
       "10    0.080024\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# checking the distribution in all the classes for test data\n",
    "\n",
    "y_test.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "latest-reason",
   "metadata": {},
   "source": [
    "##### Converting the filtered images into scalars to fit them to a ML Classifier.\n",
    "\n",
    "##### To do this I will break each 200x200 pixels image into sections of 10x10 pixels each and for the 400 resulting section I will calculate the mean and stdevs.\n",
    "\n",
    "##### This 800 unique scalar features of each image will be used for classification.\n",
    "##### The images will be converted to canny edge images for extractiong mean and stdevs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "mineral-school",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to break 200x200 pixels into sections of 10x10 each\n",
    "# and calculate mean and std\n",
    "# INPUT: img of 200x200 pixel size\n",
    "# OUTPUT: features array of means and stds of 400 sections\n",
    "\n",
    "def features_grid(img):\n",
    "    features = np.array([], dtype='float')\n",
    "    section = 1\n",
    "    \n",
    "    for y in range(0, img.shape[0], 10):\n",
    "        for x in range(0, img.shape[1], 10):\n",
    "            \n",
    "            # croppint the img\n",
    "            sec_img = img[y:y+10, x:x+10]\n",
    "            \n",
    "            # calc the mean and std\n",
    "            sec_mean = np.mean(sec_img)\n",
    "            sec_std = np.std(sec_img)\n",
    "            \n",
    "            # appending the features array\n",
    "            features = np.append(features, [sec_mean, sec_std])\n",
    "            \n",
    "        \n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "reduced-country",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to loop through images in the dataset and extract the canny edges mean and std values from 10x10 pixel sections of each image\n",
    "\n",
    "def extract_canny_edges(filename_series):\n",
    "    \n",
    "    # array of shape (1, 801) to store 400 canny edges mean values, 400 canny edges stdev values and 1 age value\n",
    "    all_imgs = np.zeros((1, 801), dtype='float')\n",
    "    \n",
    "    progress = 0\n",
    "    \n",
    "    for img_name in filename_series:\n",
    "        \n",
    "        # Defining a path to the image and reading in the coloured image.\n",
    "        \n",
    "        img_path = os.path.join(combined_faces_path, img_name)\n",
    "        img = cv2.imread(img_path)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Converting the coloured image to a grayscale image.\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Converting the grayscale image to a canny edges filtered image.\n",
    "        img = canny(img, sigma=0.9)\n",
    "        \n",
    "        # Using features_grid function for extracting the features (mean and stdev values of all 10x10 pixel sections from the image) from the canny edges filtered image.\n",
    "        img_features = features_grid(img)\n",
    "        \n",
    "        # Adding the actual age value (from the image name) into the features array.\n",
    "        age = int(img_name.split(\"_\")[0])\n",
    "        img_features = np.append(img_features, age)\n",
    "        \n",
    "        img_features = img_features.reshape(1, img_features.shape[0])\n",
    "        \n",
    "        \n",
    "        # Adding the image's features into the all_imgs features array defined above.\n",
    "        all_imgs = np.append(all_imgs, img_features, axis=0)\n",
    "        \n",
    "        # Keeping track of progress and printing relevant statements for the user.\n",
    "        progress += 1\n",
    "        if progress % 1000 == 0:\n",
    "            print(f\"Images processed for features extraction: {progress} of {len(filename_series)}\")\n",
    "    \n",
    "    \n",
    "    # Getting rid of the first row of zeros created while defining the all_imgs array above.    \n",
    "    all_imgs = all_imgs[1:]\n",
    "\n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "swiss-sleeping",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed for features extraction: 1000 of 26788\n",
      "Images processed for features extraction: 2000 of 26788\n",
      "Images processed for features extraction: 3000 of 26788\n",
      "Images processed for features extraction: 4000 of 26788\n",
      "Images processed for features extraction: 5000 of 26788\n",
      "Images processed for features extraction: 6000 of 26788\n",
      "Images processed for features extraction: 7000 of 26788\n",
      "Images processed for features extraction: 8000 of 26788\n",
      "Images processed for features extraction: 9000 of 26788\n",
      "Images processed for features extraction: 10000 of 26788\n",
      "Images processed for features extraction: 11000 of 26788\n",
      "Images processed for features extraction: 12000 of 26788\n",
      "Images processed for features extraction: 13000 of 26788\n",
      "Images processed for features extraction: 14000 of 26788\n",
      "Images processed for features extraction: 15000 of 26788\n",
      "Images processed for features extraction: 16000 of 26788\n",
      "Images processed for features extraction: 17000 of 26788\n",
      "Images processed for features extraction: 18000 of 26788\n",
      "Images processed for features extraction: 19000 of 26788\n",
      "Images processed for features extraction: 20000 of 26788\n",
      "Images processed for features extraction: 21000 of 26788\n",
      "Images processed for features extraction: 22000 of 26788\n",
      "Images processed for features extraction: 23000 of 26788\n",
      "Images processed for features extraction: 24000 of 26788\n",
      "Images processed for features extraction: 25000 of 26788\n",
      "Images processed for features extraction: 26000 of 26788\n"
     ]
    }
   ],
   "source": [
    "# Extracting the canny edge features from images in the training dataset.\n",
    "\n",
    "train_imgs = extract_canny_edges(x_train['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "supposed-experiment",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images processed for features extraction: 1000 of 6698\n",
      "Images processed for features extraction: 2000 of 6698\n",
      "Images processed for features extraction: 3000 of 6698\n",
      "Images processed for features extraction: 4000 of 6698\n",
      "Images processed for features extraction: 5000 of 6698\n",
      "Images processed for features extraction: 6000 of 6698\n"
     ]
    }
   ],
   "source": [
    "# Extracting the canny edge features from images in the testing dataset.\n",
    "\n",
    "test_imgs = extract_canny_edges(x_test['filename'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "south-leave",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(26788, 801)\n",
      "(6698, 801)\n"
     ]
    }
   ],
   "source": [
    "print(train_imgs.shape)\n",
    "print(test_imgs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "graduate-directive",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a list of columns names for the features arrays defined above.\n",
    "# The column names correspond to the sectioned image's mean and stdev values.\n",
    "# Last column is the age to be converted to target class label in the model later.\n",
    "\n",
    "feature_names = []\n",
    "section = 1\n",
    "    \n",
    "for y in range(0, 200, 10):\n",
    "    for x in range(0, 200, 10):\n",
    "        feature_names.append(f\"sec{section}_mean\")\n",
    "        feature_names.append(f\"sec{section}_std\")\n",
    "        section += 1\n",
    "\n",
    "feature_names.append('age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "egyptian-attention",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['sec396_std',\n",
       " 'sec397_mean',\n",
       " 'sec397_std',\n",
       " 'sec398_mean',\n",
       " 'sec398_std',\n",
       " 'sec399_mean',\n",
       " 'sec399_std',\n",
       " 'sec400_mean',\n",
       " 'sec400_std',\n",
       " 'age']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "moving-retreat",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "801"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attempted-filing",
   "metadata": {},
   "source": [
    "## Using Random Forest and GridSearchCV for Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "sunset-stand",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the numpy arrays to pandas dataframe.\n",
    "\n",
    "train_df = pd.DataFrame(train_imgs, columns=feature_names)\n",
    "test_df = pd.DataFrame(test_imgs, columns=feature_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "bottom-portal",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec1_mean</th>\n",
       "      <th>sec1_std</th>\n",
       "      <th>sec2_mean</th>\n",
       "      <th>sec2_std</th>\n",
       "      <th>sec3_mean</th>\n",
       "      <th>sec3_std</th>\n",
       "      <th>sec4_mean</th>\n",
       "      <th>sec4_std</th>\n",
       "      <th>sec5_mean</th>\n",
       "      <th>sec5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sec396_std</th>\n",
       "      <th>sec397_mean</th>\n",
       "      <th>sec397_std</th>\n",
       "      <th>sec398_mean</th>\n",
       "      <th>sec398_std</th>\n",
       "      <th>sec399_mean</th>\n",
       "      <th>sec399_std</th>\n",
       "      <th>sec400_mean</th>\n",
       "      <th>sec400_std</th>\n",
       "      <th>age</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.384187</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.392301</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.237487</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 801 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sec1_mean  sec1_std  sec2_mean  sec2_std  sec3_mean  sec3_std  sec4_mean  \\\n",
       "0       0.02  0.140000       0.20  0.400000       0.15  0.357071        0.1   \n",
       "1       0.27  0.443959       0.19  0.392301       0.15  0.357071        0.0   \n",
       "2       0.09  0.286182       0.00  0.000000       0.00  0.000000        0.0   \n",
       "3       0.00  0.000000       0.00  0.000000       0.00  0.000000        0.0   \n",
       "4       0.00  0.000000       0.00  0.000000       0.00  0.000000        0.0   \n",
       "\n",
       "   sec4_std  sec5_mean  sec5_std  ...  sec396_std  sec397_mean  sec397_std  \\\n",
       "0       0.3       0.14  0.346987  ...    0.384187         0.09    0.286182   \n",
       "1       0.0       0.00  0.000000  ...    0.300000         0.14    0.346987   \n",
       "2       0.0       0.00  0.000000  ...    0.000000         0.00    0.000000   \n",
       "3       0.0       0.00  0.000000  ...    0.420833         0.04    0.195959   \n",
       "4       0.0       0.10  0.300000  ...    0.000000         0.00    0.000000   \n",
       "\n",
       "   sec398_mean  sec398_std  sec399_mean  sec399_std  sec400_mean  sec400_std  \\\n",
       "0         0.15    0.357071         0.00    0.000000         0.03    0.170587   \n",
       "1         0.11    0.312890         0.10    0.300000         0.00    0.000000   \n",
       "2         0.00    0.000000         0.11    0.312890         0.06    0.237487   \n",
       "3         0.00    0.000000         0.09    0.286182         0.00    0.000000   \n",
       "4         0.00    0.000000         0.00    0.000000         0.00    0.000000   \n",
       "\n",
       "    age  \n",
       "0  32.0  \n",
       "1  38.0  \n",
       "2  20.0  \n",
       "3  67.0  \n",
       "4  29.0  \n",
       "\n",
       "[5 rows x 801 columns]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "stable-mozambique",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([dtype('float64')], dtype=object)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.dtypes.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "charged-rwanda",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a column of target class values using the function defined above.\n",
    "\n",
    "train_df['target'] = train_df['age'].map(class_labels)\n",
    "test_df['target'] = test_df['age'].map(class_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "exciting-purpose",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec1_mean</th>\n",
       "      <th>sec1_std</th>\n",
       "      <th>sec2_mean</th>\n",
       "      <th>sec2_std</th>\n",
       "      <th>sec3_mean</th>\n",
       "      <th>sec3_std</th>\n",
       "      <th>sec4_mean</th>\n",
       "      <th>sec4_std</th>\n",
       "      <th>sec5_mean</th>\n",
       "      <th>sec5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sec397_mean</th>\n",
       "      <th>sec397_std</th>\n",
       "      <th>sec398_mean</th>\n",
       "      <th>sec398_std</th>\n",
       "      <th>sec399_mean</th>\n",
       "      <th>sec399_std</th>\n",
       "      <th>sec400_mean</th>\n",
       "      <th>sec400_std</th>\n",
       "      <th>age</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.170587</td>\n",
       "      <td>32.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.392301</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>38.0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.237487</td>\n",
       "      <td>20.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>67.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>29.0</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 802 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sec1_mean  sec1_std  sec2_mean  sec2_std  sec3_mean  sec3_std  sec4_mean  \\\n",
       "0       0.02  0.140000       0.20  0.400000       0.15  0.357071        0.1   \n",
       "1       0.27  0.443959       0.19  0.392301       0.15  0.357071        0.0   \n",
       "2       0.09  0.286182       0.00  0.000000       0.00  0.000000        0.0   \n",
       "3       0.00  0.000000       0.00  0.000000       0.00  0.000000        0.0   \n",
       "4       0.00  0.000000       0.00  0.000000       0.00  0.000000        0.0   \n",
       "\n",
       "   sec4_std  sec5_mean  sec5_std  ...  sec397_mean  sec397_std  sec398_mean  \\\n",
       "0       0.3       0.14  0.346987  ...         0.09    0.286182         0.15   \n",
       "1       0.0       0.00  0.000000  ...         0.14    0.346987         0.11   \n",
       "2       0.0       0.00  0.000000  ...         0.00    0.000000         0.00   \n",
       "3       0.0       0.00  0.000000  ...         0.04    0.195959         0.00   \n",
       "4       0.0       0.10  0.300000  ...         0.00    0.000000         0.00   \n",
       "\n",
       "   sec398_std  sec399_mean  sec399_std  sec400_mean  sec400_std   age  target  \n",
       "0    0.357071         0.00    0.000000         0.03    0.170587  32.0       6  \n",
       "1    0.312890         0.10    0.300000         0.00    0.000000  38.0       7  \n",
       "2    0.000000         0.11    0.312890         0.06    0.237487  20.0       2  \n",
       "3    0.000000         0.09    0.286182         0.00    0.000000  67.0      10  \n",
       "4    0.000000         0.00    0.000000         0.00    0.000000  29.0       5  \n",
       "\n",
       "[5 rows x 802 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "looking-watson",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ML model preparation\n",
    "\n",
    "x_train_rf = train_df.drop(columns=['age', 'target'])\n",
    "y_train_rf = train_df['target']\n",
    "\n",
    "x_test_rf = test_df.drop(columns=['age', 'target'])\n",
    "y_test_rf = test_df['target']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "adaptive-attack",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec1_mean</th>\n",
       "      <th>sec1_std</th>\n",
       "      <th>sec2_mean</th>\n",
       "      <th>sec2_std</th>\n",
       "      <th>sec3_mean</th>\n",
       "      <th>sec3_std</th>\n",
       "      <th>sec4_mean</th>\n",
       "      <th>sec4_std</th>\n",
       "      <th>sec5_mean</th>\n",
       "      <th>sec5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sec396_mean</th>\n",
       "      <th>sec396_std</th>\n",
       "      <th>sec397_mean</th>\n",
       "      <th>sec397_std</th>\n",
       "      <th>sec398_mean</th>\n",
       "      <th>sec398_std</th>\n",
       "      <th>sec399_mean</th>\n",
       "      <th>sec399_std</th>\n",
       "      <th>sec400_mean</th>\n",
       "      <th>sec400_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.02</td>\n",
       "      <td>0.140000</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>...</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.384187</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.170587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.27</td>\n",
       "      <td>0.443959</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.392301</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.357071</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.346987</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.312890</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.237487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.420833</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.195959</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sec1_mean  sec1_std  sec2_mean  sec2_std  sec3_mean  sec3_std  sec4_mean  \\\n",
       "0       0.02  0.140000       0.20  0.400000       0.15  0.357071        0.1   \n",
       "1       0.27  0.443959       0.19  0.392301       0.15  0.357071        0.0   \n",
       "2       0.09  0.286182       0.00  0.000000       0.00  0.000000        0.0   \n",
       "3       0.00  0.000000       0.00  0.000000       0.00  0.000000        0.0   \n",
       "4       0.00  0.000000       0.00  0.000000       0.00  0.000000        0.0   \n",
       "\n",
       "   sec4_std  sec5_mean  sec5_std  ...  sec396_mean  sec396_std  sec397_mean  \\\n",
       "0       0.3       0.14  0.346987  ...         0.18    0.384187         0.09   \n",
       "1       0.0       0.00  0.000000  ...         0.10    0.300000         0.14   \n",
       "2       0.0       0.00  0.000000  ...         0.00    0.000000         0.00   \n",
       "3       0.0       0.00  0.000000  ...         0.23    0.420833         0.04   \n",
       "4       0.0       0.10  0.300000  ...         0.00    0.000000         0.00   \n",
       "\n",
       "   sec397_std  sec398_mean  sec398_std  sec399_mean  sec399_std  sec400_mean  \\\n",
       "0    0.286182         0.15    0.357071         0.00    0.000000         0.03   \n",
       "1    0.346987         0.11    0.312890         0.10    0.300000         0.00   \n",
       "2    0.000000         0.00    0.000000         0.11    0.312890         0.06   \n",
       "3    0.195959         0.00    0.000000         0.09    0.286182         0.00   \n",
       "4    0.000000         0.00    0.000000         0.00    0.000000         0.00   \n",
       "\n",
       "   sec400_std  \n",
       "0    0.170587  \n",
       "1    0.000000  \n",
       "2    0.237487  \n",
       "3    0.000000  \n",
       "4    0.000000  \n",
       "\n",
       "[5 rows x 800 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_rf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "wanted-exclusion",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     2798\n",
       "7     2606\n",
       "4     2558\n",
       "0     2532\n",
       "6     2502\n",
       "2     2494\n",
       "5     2440\n",
       "1     2256\n",
       "9     2226\n",
       "8     2215\n",
       "10    2161\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes in y_train.\n",
    "\n",
    "y_train_rf.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "precise-institute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.104450\n",
       "7     0.097282\n",
       "4     0.095491\n",
       "0     0.094520\n",
       "6     0.093400\n",
       "2     0.093101\n",
       "5     0.091086\n",
       "1     0.084217\n",
       "9     0.083097\n",
       "8     0.082686\n",
       "10    0.080670\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes to ensure it is same as y_test.\n",
    "\n",
    "y_train_rf.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "interesting-bernard",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3     0.100926\n",
       "0     0.098537\n",
       "4     0.098388\n",
       "2     0.095850\n",
       "5     0.093013\n",
       "7     0.089728\n",
       "8     0.087638\n",
       "6     0.087190\n",
       "9     0.085100\n",
       "1     0.083607\n",
       "10    0.080024\n",
       "Name: target, dtype: float64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the distribution of classes to ensure it is same as y_train.\n",
    "\n",
    "y_test_rf.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "limiting-crowd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scaling X_train to the standard scale.\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "ss = StandardScaler()\n",
    "x_train_sc = ss.fit_transform(x_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "beautiful-kernel",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transforming X_test to the same scale.\n",
    "\n",
    "x_test_sc = ss.transform(x_test_rf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cellular-transmission",
   "metadata": {},
   "source": [
    "### Training the model using GridSearchCV and RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "after-realtor",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "timely-prior",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a RandomForestClassifier object.\n",
    "\n",
    "rfc = RandomForestClassifier(# n_estimators=200,\n",
    "                             # max_depth=5,\n",
    "                             # ccp_alpha=0,\n",
    "                             min_samples_split=2,\n",
    "                             min_samples_leaf=1,\n",
    "                             random_state=17\n",
    "                            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "latter-syracuse",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing ranges of hyperparameters of RandomForestClassifier for GridSearchCV.\n",
    "\n",
    "rfc_params = {'n_estimators' : [100, 200, 300],\n",
    "              'max_depth' : [7, 9, 11],\n",
    "              'ccp_alpha' : [0, 0.001, 0.01],\n",
    "              # 'min_samples_split' : [2, 5, 10, 15, 20],\n",
    "              # 'min_samples_leaf' : [2, 3, 4, 5, 6]\n",
    "             }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "regulated-poverty",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a GridSearchCV object for the RandomForestClassifier object defined above.\n",
    "\n",
    "rfc_gs = GridSearchCV(rfc, param_grid=rfc_params, n_jobs=-1, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "natural-queen",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5,\n",
       "             estimator=RandomForestClassifier(ccp_alpha=0, random_state=42),\n",
       "             n_jobs=-1,\n",
       "             param_grid={'max_depth': [5, 7, 9],\n",
       "                         'n_estimators': [50, 100, 200]})"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting X_train_sc and y_train on GridSearchCV object with RandomForestClassifier defined above.\n",
    "\n",
    "rfc_gs.fit(x_train_sc, y_train_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "talented-engagement",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 9, 'n_estimators': 200}"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best combination of hyperparameters suggested by GridSearchCV.\n",
    "\n",
    "rfc_gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "curious-while",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.39271336746658153"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best accuracy score obtained by the above combination of hyperparameters.\n",
    "\n",
    "rfc_gs.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "horizontal-dispute",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6364790204569211"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Scoring the model on training dataset.\n",
    "# Training Accuracy\n",
    "\n",
    "rfc_train_acc = rfc_gs.score(x_train_sc, y_train_rf)\n",
    "rfc_train_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "proprietary-botswana",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.40848014332636606"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Actual Testing Accuracy\n",
    "\n",
    "rfc_test_acc = rfc_gs.score(x_test_sc, y_test_rf)\n",
    "rfc_test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "animated-opening",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier summary of accuracy scores:\n",
      "GridSearchCV best accuracy (cv=5) = 0.393\n",
      "\n",
      "Using GridSearchCV best params suggested,\n",
      "Training accuracy = 0.636\n",
      "Testing accuracy = 0.408\n"
     ]
    }
   ],
   "source": [
    "# Summary scores from GridSearchCV with RandomForestClassifier.\n",
    "\n",
    "print(\"RandomForestClassifier summary of accuracy scores:\")\n",
    "print(f\"GridSearchCV best accuracy (cv=5) = {round(rfc_gs.best_score_, 3)}\")\n",
    "print(\"\\nUsing GridSearchCV best params suggested,\")\n",
    "print(f\"Training accuracy = {round(rfc_train_acc, 3)}\")\n",
    "# print(f\"Est. Test accuracy (cv=5) = {round(rfc_est_test_acc , 3)}\")\n",
    "print(f\"Testing accuracy = {round(rfc_test_acc, 3)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "heavy-trash",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generating predictions on testing dataset using the model above.\n",
    "\n",
    "rfc_pred = rfc_gs.predict(x_test_sc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "productive-remedy",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([8, 8, 7, ..., 8, 3, 0], dtype=int64)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(rfc_pred))\n",
    "rfc_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "authorized-titanium",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6698"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "incident-comparison",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[602,   8,   5,  23,  10,   0,   1,   7,   0,   2,   2],\n",
       "       [123, 270,  40,  63,  10,   0,   0,  36,   5,   6,   7],\n",
       "       [ 53,  38, 286, 152,  21,   1,   4,  48,  15,   9,  15],\n",
       "       [ 25,  24,  33, 433,  69,   2,  14,  53,  10,  10,   3],\n",
       "       [ 33,  11,  19, 293, 137,   1,  14, 120,  11,   8,  12],\n",
       "       [ 21,  25,  26, 253,  67,  21,  18, 138,  24,  10,  20],\n",
       "       [ 23,  12,  22, 194,  55,   4,  42, 158,  39,  24,  11],\n",
       "       [ 20,  13,  18, 123,  59,   3,   7, 250,  52,  25,  31],\n",
       "       [ 14,   8,  28,  71,  34,   1,   8, 152, 184,  32,  55],\n",
       "       [ 15,   8,  16,  70,  28,   1,   6, 109,  48, 167, 102],\n",
       "       [ 10,   6,  21,  27,  18,   1,   1,  70,  24,  14, 344]],\n",
       "      dtype=int64)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Generating a confusion matrix based on above predictions.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "conf_mat_rfc = confusion_matrix(y_test_rf, rfc_pred)\n",
    "conf_mat_rfc"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "material-january",
   "metadata": {},
   "source": [
    "# To check the predictions on a random set of images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "psychological-feelings",
   "metadata": {},
   "outputs": [],
   "source": [
    "# features for predicting the class of unknown img\n",
    "\n",
    "feature_pred = []\n",
    "section = 1\n",
    "    \n",
    "for y in range(0, 200, 10):\n",
    "    for x in range(0, 200, 10):\n",
    "        feature_pred.append(f\"sec{section}_mean\")\n",
    "        feature_pred.append(f\"sec{section}_std\")\n",
    "        section += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "lonely-scanning",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to loop through images in the dataset and extract the canny edges mean and std values from 10x10 pixel sections of each image\n",
    "\n",
    "def extract_canny_edges_pred(filename_series):\n",
    "    \n",
    "    # array of shape (1, 801) to store 400 canny edges mean values, 400 canny edges stdev values\n",
    "    all_imgs = np.zeros((1, 800), dtype='float') \n",
    "    \n",
    "    progress = 0\n",
    "    \n",
    "    for img_name in filename_series:\n",
    "        \n",
    "        # Defining a path to the image and reading in the coloured image.\n",
    "        \n",
    "        img = cv2.imread(img_name)\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        # Converting the coloured image to a grayscale image.\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "        \n",
    "        # Converting the grayscale image to a canny edges filtered image.\n",
    "        img = canny(img, sigma=0.9)\n",
    "        \n",
    "        # Using features_grid function for extracting the features from the canny edges filtered image.\n",
    "        img_features = features_grid(img)\n",
    "        \n",
    "        \n",
    "        img_features = img_features.reshape(1, img_features.shape[0])\n",
    "        \n",
    "        \n",
    "        # Adding the image's features into the all_imgs features array defined above.\n",
    "        all_imgs = np.append(all_imgs, img_features, axis=0)\n",
    "        \n",
    "        # Keeping track of progress and printing relevant statements for the user.\n",
    "        progress += 1\n",
    "        if progress % 5 == 0:\n",
    "            print(f\"Images processed for features extraction: {progress} of {len(filename_series)}\")\n",
    "    \n",
    "    \n",
    "    # Getting rid of the first row of zeros created while defining the all_imgs array above.    \n",
    "    all_imgs = all_imgs[1:]\n",
    "\n",
    "    return all_imgs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "iraqi-turtle",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_imgs = ['images.jpg', 'images1.jpg', 'images2.jpg']\n",
    "pred_img_series = pd.DataFrame(pred_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "velvet-server",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_imgs = extract_canny_edges_pred(pred_img_series[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "sufficient-minute",
   "metadata": {},
   "outputs": [],
   "source": [
    "ce_imgs_df = pd.DataFrame(ce_imgs, columns=feature_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "earlier-manner",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sec1_mean</th>\n",
       "      <th>sec1_std</th>\n",
       "      <th>sec2_mean</th>\n",
       "      <th>sec2_std</th>\n",
       "      <th>sec3_mean</th>\n",
       "      <th>sec3_std</th>\n",
       "      <th>sec4_mean</th>\n",
       "      <th>sec4_std</th>\n",
       "      <th>sec5_mean</th>\n",
       "      <th>sec5_std</th>\n",
       "      <th>...</th>\n",
       "      <th>sec396_mean</th>\n",
       "      <th>sec396_std</th>\n",
       "      <th>sec397_mean</th>\n",
       "      <th>sec397_std</th>\n",
       "      <th>sec398_mean</th>\n",
       "      <th>sec398_std</th>\n",
       "      <th>sec399_mean</th>\n",
       "      <th>sec399_std</th>\n",
       "      <th>sec400_mean</th>\n",
       "      <th>sec400_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.336303</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.286182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.237487</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.255147</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.324962</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   sec1_mean  sec1_std  sec2_mean  sec2_std  sec3_mean  sec3_std  sec4_mean  \\\n",
       "0        0.0       0.0        0.0       0.0        0.0       0.0        0.0   \n",
       "1        0.0       0.0        0.0       0.0        0.0       0.0        0.0   \n",
       "2        0.0       0.0        0.0       0.0        0.0       0.0        0.0   \n",
       "\n",
       "   sec4_std  sec5_mean  sec5_std  ...  sec396_mean  sec396_std  sec397_mean  \\\n",
       "0       0.0        0.0       0.0  ...         0.00    0.000000         0.00   \n",
       "1       0.0        0.0       0.0  ...         0.00    0.000000         0.00   \n",
       "2       0.0        0.0       0.0  ...         0.06    0.237487         0.07   \n",
       "\n",
       "   sec397_std  sec398_mean  sec398_std  sec399_mean  sec399_std  sec400_mean  \\\n",
       "0    0.000000         0.13    0.336303          0.1         0.3         0.00   \n",
       "1    0.000000         0.00    0.000000          0.0         0.0         0.09   \n",
       "2    0.255147         0.12    0.324962          0.0         0.0         0.00   \n",
       "\n",
       "   sec400_std  \n",
       "0    0.000000  \n",
       "1    0.286182  \n",
       "2    0.000000  \n",
       "\n",
       "[3 rows x 800 columns]"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ce_imgs_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "deluxe-invite",
   "metadata": {},
   "outputs": [],
   "source": [
    "img_pred_sc = ss.fit_transform(ce_imgs_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "awful-cleveland",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6, 7, 3], dtype=int64)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = rfc_gs.predict(img_pred_sc)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "decreased-church",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
